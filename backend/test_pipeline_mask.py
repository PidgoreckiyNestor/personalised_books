#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–∞—Å–∫–∏ —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É (comfy_runner._build_face_mask)
"""
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from PIL import Image
import cv2
import numpy as np

# –°–ø—Ä–æ–±—É—î–º–æ —ñ–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ MediaPipe
MEDIAPIPE_AVAILABLE = False
mp = None
try:
    import mediapipe
    mp = mediapipe
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —è–∫–∏–π API –¥–æ—Å—Ç—É–ø–Ω–∏–π
    if hasattr(mp, 'solutions') and hasattr(mp.solutions, 'face_detection'):
        MEDIAPIPE_AVAILABLE = "solutions"
    elif hasattr(mp, 'tasks'):
        MEDIAPIPE_AVAILABLE = "tasks"
    print(f"‚úì MediaPipe {mp.__version__} (API: {MEDIAPIPE_AVAILABLE or 'none'})")
except ImportError:
    print("‚ö†Ô∏è  MediaPipe –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. pip install mediapipe")


def detect_face_mediapipe(img_rgb: np.ndarray):
    """–î–µ—Ç–µ–∫—Ü—ñ—è –æ–±–ª–∏—á—á—è —á–µ—Ä–µ–∑ MediaPipe - –±–µ—Ä–µ –Ω–∞–π–∫—Ä–∞—â–µ –∑ —É—Å—ñ—Ö –¥–µ—Ç–µ–∫—Ü—ñ–π"""
    if not MEDIAPIPE_AVAILABLE:
        return None

    h, w = img_rgb.shape[:2]
    all_detections = []

    # –ù–æ–≤–∏–π API (tasks) - MediaPipe 0.10+
    if MEDIAPIPE_AVAILABLE == "tasks":
        try:
            from mediapipe.tasks import python
            from mediapipe.tasks.python import vision

            model_path = os.path.join(os.path.dirname(__file__), "models", "blaze_face_short_range.tflite")
            if not os.path.exists(model_path):
                print(f"      ‚ö†Ô∏è Model not found: {model_path}")
                return None

            # –ù–∏–∑—å–∫–∏–π –ø–æ—Ä—ñ–≥ —â–æ–± –∑–Ω–∞–π—Ç–∏ –≤—Å—ñ –º–æ–∂–ª–∏–≤—ñ –æ–±–ª–∏—á—á—è
            base_options = python.BaseOptions(model_asset_path=model_path)
            options = vision.FaceDetectorOptions(
                base_options=base_options,
                min_detection_confidence=0.15  # –ù–∏–∑—å–∫–∏–π –ø–æ—Ä—ñ–≥
            )

            detector = vision.FaceDetector.create_from_options(options)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_rgb)
            results = detector.detect(mp_image)

            for det in results.detections:
                bbox = det.bounding_box
                x1, y1 = bbox.origin_x, bbox.origin_y
                x2, y2 = x1 + bbox.width, y1 + bbox.height
                conf = det.categories[0].score
                face_area = bbox.width * bbox.height

                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª—ñ –∞–±–æ –≤–µ–ª–∏–∫—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó
                img_area = w * h
                area_ratio = face_area / img_area

                if 0.005 < area_ratio < 0.5:  # –û–±–ª–∏—á—á—è –≤—ñ–¥ 0.5% –¥–æ 50% –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                    all_detections.append({
                        "bbox": (int(x1), int(y1), int(x2), int(y2)),
                        "conf": conf,
                        "area": face_area,
                        "area_ratio": area_ratio
                    })

        except Exception as e:
            print(f"      ‚ö†Ô∏è MediaPipe Tasks error: {e}")

    # –°—Ç–∞—Ä–∏–π API (solutions)
    if MEDIAPIPE_AVAILABLE == "solutions":
        try:
            mp_face = mp.solutions.face_detection
            with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.15) as detector:
                results = detector.process(img_rgb)
                for det in (results.detections or []):
                    bbox = det.location_data.relative_bounding_box
                    x1 = int(bbox.xmin * w)
                    y1 = int(bbox.ymin * h)
                    x2 = int((bbox.xmin + bbox.width) * w)
                    y2 = int((bbox.ymin + bbox.height) * h)
                    conf = det.score[0]
                    face_area = (x2 - x1) * (y2 - y1)
                    area_ratio = face_area / (w * h)

                    if 0.005 < area_ratio < 0.5:
                        all_detections.append({
                            "bbox": (x1, y1, x2, y2),
                            "conf": conf,
                            "area": face_area,
                            "area_ratio": area_ratio
                        })
        except Exception as e:
            print(f"      ‚ö†Ô∏è MediaPipe Solutions error: {e}")

    if not all_detections:
        return None

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ confidence (–≥–æ–ª–æ–≤–Ω–∏–π –∫—Ä–∏—Ç–µ—Ä—ñ–π)
    # –ü—Ä–∏ –æ–¥–Ω–∞–∫–æ–≤–æ–º—É confidence - –±–µ—Ä–µ–º–æ –∑ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–º —Ä–æ–∑–º—ñ—Ä–æ–º (5-15% –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è)
    for d in all_detections:
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –æ–±–ª–∏—á—á—è: 5-15% –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        optimal_ratio = 0.10
        size_penalty = abs(d["area_ratio"] - optimal_ratio) / optimal_ratio
        # –°–∫–æ—Ä: confidence –∑ –Ω–µ–≤–µ–ª–∏–∫–∏–º —à—Ç—Ä–∞—Ñ–æ–º –∑–∞ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä
        d["score"] = d["conf"] - (size_penalty * 0.1)

    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥—É–∂–µ –Ω–∏–∑—å–∫–∏–π confidence
    good_detections = [d for d in all_detections if d["conf"] >= 0.4]
    if not good_detections:
        good_detections = all_detections  # –Ø–∫—â–æ –≤—Å—ñ –ø–æ–≥–∞–Ω—ñ - –±–µ—Ä–µ–º–æ —â–æ —î

    best = max(good_detections, key=lambda d: d["score"])

    # Debug: –ø–æ–∫–∞–∑–∞—Ç–∏ –≤—Å—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó
    if len(all_detections) > 1:
        print(f"      üìä –í—Å—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó:")
        for i, d in enumerate(sorted(all_detections, key=lambda x: -x["conf"])):
            marker = "‚Üí" if d == best else " "
            print(f"         {marker} [{i+1}] conf={d['conf']:.2f}, area={d['area_ratio']*100:.1f}%, bbox={d['bbox']}")
    else:
        print(f"      üìä conf={best['conf']:.2f}, area={best['area_ratio']*100:.1f}%")

    return best["bbox"], best["conf"]


def detect_face_haar(gray: np.ndarray):
    """Fallback –¥–µ—Ç–µ–∫—Ü—ñ—è —á–µ—Ä–µ–∑ Haar Cascades"""
    cascades_to_try = [
        ("haarcascade_frontalface_alt2.xml", 1.05, 3),
        ("haarcascade_frontalface_default.xml", 1.1, 4),
        ("haarcascade_frontalface_alt.xml", 1.1, 3),
        ("haarcascade_profileface.xml", 1.1, 3),
    ]

    for cascade_name, scale, neighbors in cascades_to_try:
        try:
            cascade_path = cv2.data.haarcascades + cascade_name
            cascade = cv2.CascadeClassifier(cascade_path)

            for min_size in [(30, 30), (50, 50), (80, 80)]:
                dets = cascade.detectMultiScale(
                    gray, scaleFactor=scale, minNeighbors=neighbors,
                    minSize=min_size, flags=cv2.CASCADE_SCALE_IMAGE
                )
                if len(dets) > 0:
                    dets = sorted(dets, key=lambda r: r[2] * r[3], reverse=True)
                    x, y, bw, bh = dets[0]
                    return (int(x), int(y), int(x + bw), int(y + bh)), cascade_name
        except Exception:
            continue
    return None


def _build_face_mask(pil_img: Image.Image):
    """
    –ö–û–ü–Ü–Ø –∑ comfy_runner.py - —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–∞—Å–∫–∏ –¥–ª—è —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó
    """
    try:
        rgb = pil_img.convert("RGB")
        img_np = np.array(rgb)
        img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

        h, w = img_np.shape[:2]

        x1 = y1 = x2 = y2 = None
        detection_method = None
        confidence = None

        # 1. MediaPipe (–Ω–∞–π–∫—Ä–∞—â–∏–π –¥–ª—è —Ä–µ–∞–ª—å–Ω–∏—Ö —Ñ–æ—Ç–æ)
        mp_result = detect_face_mediapipe(img_np)
        if mp_result:
            (x1, y1, x2, y2), confidence = mp_result
            detection_method = f"MediaPipe (conf={confidence:.2f})"

            # –Ø–∫—â–æ confidence –Ω–∏–∑—å–∫–∏–π - –º–æ–∂–ª–∏–≤–æ —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—è, –ø—Ä–æ–±—É—î–º–æ Haar
            if confidence < 0.5:
                print(f"      ‚ö†Ô∏è Low confidence ({confidence:.2f}), trying Haar...")
                haar_result = detect_face_haar(gray)
                if haar_result:
                    h_bbox, h_method = haar_result
                    h_area = (h_bbox[2] - h_bbox[0]) * (h_bbox[3] - h_bbox[1])
                    mp_area = (x2 - x1) * (y2 - y1)
                    # –Ø–∫—â–æ Haar –∑–Ω–∞–π—à–æ–≤ –º–µ–Ω—à–µ –æ–±–ª–∏—á—á—è - –≤–æ–Ω–æ —Å–∫–æ—Ä—ñ—à –∑–∞ –≤—Å–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—à–µ
                    if h_area < mp_area * 0.7:
                        (x1, y1, x2, y2) = h_bbox
                        detection_method = f"Haar (MediaPipe low conf)"
                        print(f"      ‚úì Haar –æ–±—Ä–∞–≤ –º–µ–Ω—à–∏–π bbox")

        # 2. Fallback –Ω–∞ Haar —è–∫—â–æ MediaPipe –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π—à–æ–≤
        if x1 is None:
            haar_result = detect_face_haar(gray)
            if haar_result:
                (x1, y1, x2, y2), cascade_name = haar_result
                detection_method = f"Haar: {cascade_name}"

        if x1 is None or y1 is None or x2 is None or y2 is None or x2 <= x1 or y2 <= y1:
            # Fallback: centered ellipse
            cx = w // 2
            cy = int(h * 0.45)
            ax = max(1, int(w * 0.18))
            ay = max(1, int(h * 0.22))
            detection = {"detected": False, "fallback": True, "cx": cx, "cy": cy, "ax": ax, "ay": ay}
        else:
            bw = x2 - x1
            bh = y2 - y1
            cx = x1 + bw // 2 - int(bw * 0.15)  # –©–µ –ª—ñ–≤—ñ—à–µ –Ω–∞ 15%
            cy = y1 + int(bh * 0.20)
            ax = max(1, int(bw * 0.9))  # –®–∏—Ä—à–µ –¥–ª—è –≤–æ–ª–æ—Å—Å—è –∑–ª—ñ–≤–∞
            ay = max(1, int(bh * 1.1))
            detection = {"detected": True, "bbox": (x1, y1, x2, y2), "cx": cx, "cy": cy, "ax": ax, "ay": ay, "method": detection_method}

        mask = np.zeros((h, w), dtype=np.uint8)
        cv2.ellipse(mask, (int(cx), int(cy)), (int(ax), int(ay)), 0, 0, 360, 255, -1)

        sigma = max(8, int(min(w, h) * 0.03))
        mask = cv2.GaussianBlur(mask, (0, 0), sigmaX=sigma, sigmaY=sigma)

        return Image.fromarray(mask), detection

    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None, {"error": str(e)}


def create_red_mask(mask_gray: Image.Image) -> Image.Image:
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î grayscale –º–∞—Å–∫—É –≤ RED-only —Ñ–æ—Ä–º–∞—Ç –¥–ª—è ComfyUI"""
    mask_np = np.array(mask_gray)
    h, w = mask_np.shape
    mask_red = np.zeros((h, w, 3), dtype=np.uint8)
    mask_red[:, :, 0] = mask_np  # –¢—ñ–ª—å–∫–∏ —á–µ—Ä–≤–æ–Ω–∏–π –∫–∞–Ω–∞–ª
    return Image.fromarray(mask_red)


def create_visualization(original: Image.Image, mask: Image.Image) -> Image.Image:
    """–°—Ç–≤–æ—Ä—é—î –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é –º–∞—Å–∫–∏ –ø–æ–≤–µ—Ä—Ö –æ—Ä–∏–≥—ñ–Ω–∞–ª—É"""
    viz = original.convert("RGBA")
    mask_np = np.array(mask)
    h, w = mask_np.shape
    overlay = np.zeros((h, w, 4), dtype=np.uint8)
    overlay[:, :, 0] = mask_np  # Red
    overlay[:, :, 3] = (mask_np * 0.6).astype(np.uint8)  # Alpha
    return Image.alpha_composite(viz, Image.fromarray(overlay, 'RGBA'))


def main():
    assets_dir = os.path.join(os.path.dirname(__file__), "assets")
    output_dir = os.path.join(os.path.dirname(__file__), "test_output")
    os.makedirs(output_dir, exist_ok=True)
    
    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—ó (–Ω–µ —Ñ–æ—Ç–æ –ª—é–¥–µ–π)
    files = os.listdir(assets_dir)
    illustrations = [f for f in files if f.lower().startswith('screenshot') and f.endswith('.png')]
    
    if not illustrations:
        print("‚ùå –ù–µ–º–∞—î —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ–π –≤ assets/ (—Ñ–∞–π–ª–∏ Screenshot*.png)")
        return
    
    print("=" * 60)
    print("üé≠ –¢–ï–°–¢ –°–¢–í–û–†–ï–ù–ù–Ø –ú–ê–°–ö–ò")
    print("=" * 60)
    
    for filename in illustrations:
        img_path = os.path.join(assets_dir, filename)
        print(f"\nüì∑ {filename}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ
        pil_img = Image.open(img_path)
        print(f"   –†–æ–∑–º—ñ—Ä: {pil_img.size}")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–∞—Å–∫—É
        mask, detection = _build_face_mask(pil_img)
        
        if mask is None:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–∞—Å–∫–∏")
            continue
        
        if detection.get("detected"):
            print(f"   ‚úÖ –û–±–ª–∏—á—á—è –∑–Ω–∞–π–¥–µ–Ω–æ!")
            print(f"      Bbox: {detection.get('bbox')}")
            print(f"      Method: {detection.get('method')}")
        else:
            print(f"   ‚ö†Ô∏è  Fallback (–æ–±–ª–∏—á—á—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ)")
        
        print(f"      Center: ({detection['cx']}, {detection['cy']})")
        print(f"      Axes: ({detection['ax']}, {detection['ay']})")
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        base = os.path.splitext(filename)[0]
        
        # Grayscale –º–∞—Å–∫–∞
        mask.save(os.path.join(output_dir, f"{base}_mask_gray.png"))
        
        # RED-only –º–∞—Å–∫–∞ –¥–ª—è ComfyUI
        mask_red = create_red_mask(mask)
        mask_red.save(os.path.join(output_dir, f"{base}_mask_RED.png"))
        
        # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
        viz = create_visualization(pil_img, mask)
        viz.save(os.path.join(output_dir, f"{base}_visualization.png"))
        
        print(f"   üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ test_output/")
    
    print("\n" + "=" * 60)
    print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
