{
  "3": {
    "inputs": {
      "seed": 419478514358630,
      "steps": 30,
      "cfg": 5.5,
      "sampler_name": "dpmpp_3m_sde_gpu",
      "scheduler": "exponential",
      "denoise": 0.55,
      "model": [
        "61",
        0
      ],
      "positive": [
        "51",
        0
      ],
      "negative": [
        "51",
        1
      ],
      "latent_image": [
        "18",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "dreamshaper_8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "young girl, 5-6 years old, long dark brown curly hair, voluminous curls, natural hair texture, big dark brown almond-shaped eyes, olive tan skin, small nose, soft round face, long eyelashes, natural dark eyebrows",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "65",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "10": {
    "inputs": {
      "image": "page_19_base.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "16": {
    "inputs": {
      "kernel_size": 15,
      "sigma": 10,
      "mask": [
        "148",
        0
      ]
    },
    "class_type": "ImpactGaussianBlurMask",
    "_meta": {
      "title": "Gaussian Blur Mask"
    }
  },
  "18": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "19",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "pixels": [
        "10",
        0
      ],
      "mask": [
        "16",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "InpaintModelConditioning"
    }
  },
  "19": {
    "inputs": {
      "text": "cross-eyed, mismatched eyes, squint, dead eyes, glossy eyes, lazy eye, asymmetric face, deformed, blurry, bad anatomy, extra fingers, malformed hands, poorly drawn face, ugly, disfigured, watermark, text, low quality, jpeg artifacts, plastic skin, flat lighting, uncanny valley",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "28": {
    "inputs": {
      "detect_hand": "disable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 640,
      "bbox_detector": "None",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "10",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "31": {
    "inputs": {
      "cnet": "control_v11p_sd15_lineart.pth"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "32": {
    "inputs": {
      "strength": 0.31,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "18",
        0
      ],
      "negative": [
        "18",
        1
      ],
      "control_net": [
        "31",
        0
      ],
      "image": [
        "28",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "48": {
    "inputs": {
      "safe": "enable",
      "resolution": 512,
      "image": [
        "10",
        0
      ]
    },
    "class_type": "PiDiNetPreprocessor",
    "_meta": {
      "title": "PiDiNet Soft-Edge Lines"
    }
  },
  "51": {
    "inputs": {
      "strength": 0.3,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "32",
        0
      ],
      "negative": [
        "32",
        1
      ],
      "control_net": [
        "58",
        0
      ],
      "image": [
        "48",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "58": {
    "inputs": {
      "cnet": "control_v11p_sd15_lineart.pth"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "61": {
    "inputs": {
      "weight": 0.9,
      "weight_faceidv2": 1,
      "weight_type": "ease in-out",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "K+mean(V) w/ C penalty",
      "model": [
        "63",
        0
      ],
      "ipadapter": [
        "63",
        1
      ],
      "image": [
        "117",
        0
      ],
      "attn_mask": [
        "16",
        0
      ],
      "clip_vision": [
        "152",
        0
      ],
      "insightface": [
        "151",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "63": {
    "inputs": {
      "preset": "FACEID PLUS V2",
      "lora_strength": 0.44,
      "provider": "CUDA",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "64": {
    "inputs": {
      "image": "Screenshot 2026-02-04 at 01.01.29.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "65": {
    "inputs": {
      "method": "skimage",
      "factor": 1,
      "device": "cpu",
      "image": [
        "8",
        0
      ],
      "reference": [
        "10",
        0
      ]
    },
    "class_type": "ImageHistogramMatch+",
    "_meta": {
      "title": "üîß Image Histogram Match"
    }
  },
  "117": {
    "inputs": {
      "crop_padding_factor": 0.1,
      "cascade_xml": "haarcascade_frontalface_alt2.xml",
      "image": [
        "64",
        0
      ]
    },
    "class_type": "Image Crop Face",
    "_meta": {
      "title": "Image Crop Face"
    }
  },
  "136": {
    "inputs": {
      "model_name": "RealESRGAN_x2.pth"
    },
    "class_type": "Upscale Model Loader",
    "_meta": {
      "title": "Upscale Model Loader"
    }
  },
  "137": {
    "inputs": {
      "per_batch": 1,
      "downscale_ratio": 1,
      "downscale_method": "lanczos",
      "precision": "float32",
      "upscale_model": [
        "136",
        0
      ],
      "images": [
        "65",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModelBatched",
    "_meta": {
      "title": "Image Upscale With Model Batched"
    }
  },
  "140": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "137",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "148": {
    "inputs": {
      "channel": "red",
      "image": [
        "150",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "150": {
    "inputs": {
      "image": "Group 1 (2).png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "151": {
    "inputs": {
      "provider": "CUDA",
      "model_name": "buffalo_l"
    },
    "class_type": "IPAdapterInsightFaceLoader",
    "_meta": {
      "title": "IPAdapter InsightFace Loader"
    }
  },
  "152": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  }
}