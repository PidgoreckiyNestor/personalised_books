{
  "3": {
    "inputs": {
      "seed": 843515276250665,
      "steps": 30,
      "cfg": 4,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "exponential",
      "denoise": 0.6,
      "model": [
        "61",
        0
      ],
      "positive": [
        "51",
        0
      ],
      "negative": [
        "51",
        1
      ],
      "latent_image": [
        "18",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "dreamshaper_8.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "5 year old girl, long dark brown tightly curly voluminous hair, black-brown expressive eyes, warm olive skin, joyful bright smile, sparkling happy eyes, excited expression, rosy cheeks",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "183",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "10": {
    "inputs": {
      "image": "illustration_dc45be36b9a24811b43540c6034ee317.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "18": {
    "inputs": {
      "noise_mask": true,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "19",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "pixels": [
        "168",
        0
      ],
      "mask": [
        "168",
        1
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "InpaintModelConditioning"
    }
  },
  "19": {
    "inputs": {
      "text": "deformed, ugly, blurry, bad anatomy, extra fingers, extra limbs, disfigured face, distorted face, bad eyes, crossed eyes, bad teeth, extra teeth, old looking, adult features, realistic photo, scary, dark, horror",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "28": {
    "inputs": {
      "detect_hand": "disable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 640,
      "bbox_detector": "None",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "168",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "31": {
    "inputs": {
      "cnet": "control_v11p_sd15_lineart.pth"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "32": {
    "inputs": {
      "strength": 0.31,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "18",
        0
      ],
      "negative": [
        "18",
        1
      ],
      "control_net": [
        "31",
        0
      ],
      "image": [
        "28",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "48": {
    "inputs": {
      "safe": "enable",
      "resolution": 512,
      "image": [
        "168",
        0
      ]
    },
    "class_type": "PiDiNetPreprocessor",
    "_meta": {
      "title": "PiDiNet Soft-Edge Lines"
    }
  },
  "51": {
    "inputs": {
      "strength": 0.3,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "32",
        0
      ],
      "negative": [
        "32",
        1
      ],
      "control_net": [
        "58",
        0
      ],
      "image": [
        "48",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "58": {
    "inputs": {
      "cnet": "control_v11p_sd15_lineart.pth"
    },
    "class_type": "ACN_ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "61": {
    "inputs": {
      "weight": 1.1,
      "weight_faceidv2": 1,
      "weight_type": "ease in-out",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "K+V",
      "model": [
        "63",
        0
      ],
      "ipadapter": [
        "63",
        1
      ],
      "image": [
        "117",
        0
      ],
      "attn_mask": [
        "168",
        1
      ],
      "clip_vision": [
        "152",
        0
      ],
      "insightface": [
        "151",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "63": {
    "inputs": {
      "preset": "FACEID PLUS V2",
      "lora_strength": 0.75,
      "provider": "CUDA",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "64": {
    "inputs": {
      "image": "child_a7b081dbdb2c4290a273b1501fd2f605.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "117": {
    "inputs": {
      "crop_padding_factor": 0.1,
      "cascade_xml": "haarcascade_frontalface_alt2.xml",
      "image": [
        "64",
        0
      ]
    },
    "class_type": "Image Crop Face",
    "_meta": {
      "title": "Image Crop Face"
    }
  },
  "136": {
    "inputs": {
      "model_name": "RealESRGAN_x2.pth"
    },
    "class_type": "Upscale Model Loader",
    "_meta": {
      "title": "Upscale Model Loader"
    }
  },
  "137": {
    "inputs": {
      "per_batch": 1,
      "downscale_ratio": 1,
      "downscale_method": "lanczos",
      "precision": "float32",
      "upscale_model": [
        "136",
        0
      ],
      "images": [
        "8",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModelBatched",
    "_meta": {
      "title": "Image Upscale With Model Batched"
    }
  },
  "148": {
    "inputs": {
      "channel": "red",
      "image": [
        "150",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "150": {
    "inputs": {
      "image": "mask_8ade1da2947e45eca25c8cb1be58d716.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "151": {
    "inputs": {
      "provider": "CUDA",
      "model_name": "buffalo_l"
    },
    "class_type": "IPAdapterInsightFaceLoader",
    "_meta": {
      "title": "IPAdapter InsightFace Loader"
    }
  },
  "152": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "166": {
    "inputs": {
      "destination": [
        "182",
        0
      ],
      "source": [
        "137",
        0
      ],
      "mask": [
        "179",
        0
      ],
      "bbox": [
        "168",
        2
      ]
    },
    "class_type": "ImageUncropByMask",
    "_meta": {
      "title": "Image Uncrop By Mask"
    }
  },
  "168": {
    "inputs": {
      "base_resolution": 512,
      "padding": 50,
      "min_crop_resolution": 128,
      "max_crop_resolution": 512,
      "image": [
        "182",
        0
      ],
      "mask": [
        "148",
        0
      ]
    },
    "class_type": "ImageCropByMaskAndResize",
    "_meta": {
      "title": "Image Crop By Mask And Resize"
    }
  },
  "179": {
    "inputs": {
      "kernel_size": 41,
      "sigma": 30,
      "mask": [
        "168",
        1
      ]
    },
    "class_type": "ImpactGaussianBlurMask",
    "_meta": {
      "title": "Gaussian Blur Mask"
    }
  },
  "182": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "interpolation": "nearest",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "10",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "183": {
    "inputs": {
      "method": "skimage",
      "factor": 1,
      "device": "gpu",
      "image": [
        "166",
        0
      ],
      "reference": [
        "182",
        0
      ]
    },
    "class_type": "ImageHistogramMatch+",
    "_meta": {
      "title": "üîß Image Histogram Match"
    }
  },
  "184": {
    "inputs": {
      "images": [
        "117",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}